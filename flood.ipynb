{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c301b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running locally, uncomment installs as needed\n",
    "# If running repeatedly, consider using a venv.\n",
    "%pip install fastapi uvicorn pillow python-dotenv google-genai nest_asyncio pyngrok --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply asyncio patch so uvicorn can run inside Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env if present\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure GEMINI_API_KEY is available\n",
    "if \"GEMINI_API_KEY\" not in os.environ or not os.environ[\"GEMINI_API_KEY\"]:\n",
    "    # Optionally, set here interactively\n",
    "    os.environ[\"GEMINI_API_KEY\"] = input(\"Enter GEMINI_API_KEY: \").strip()\n",
    "\n",
    "# Default host/port for the server\n",
    "os.environ.setdefault(\"HOST\", \"0.0.0.0\")\n",
    "os.environ.setdefault(\"PORT\", \"8000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile, HTTPException, Header\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# New google-genai client (modern)\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"flood-api\")\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = genai.Client(api_key=os.environ[\"AIzaSyB6qaVwyrNX8A0aQ6fPbvIB0wcvf15ch2U\"])\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Flood Detection API\",\n",
    "    description=\"Simple flood risk assessment using Gemini AI\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class CoordinateRequest(BaseModel):\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "\n",
    "class AnalysisResponse(BaseModel):\n",
    "    success: bool\n",
    "    risk_level: str\n",
    "    description: str\n",
    "    recommendations: List[str]\n",
    "    elevation: float\n",
    "    distance_from_water: float\n",
    "    message: str\n",
    "\n",
    "def parse_gemini_response(response_text: str) -> dict:\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group()\n",
    "            parsed_data = json.loads(json_str)\n",
    "            return {\n",
    "                \"risk_level\": parsed_data.get(\"risk_level\", \"Medium\"),\n",
    "                \"description\": parsed_data.get(\"description\", \"Analysis completed\"),\n",
    "                \"recommendations\": parsed_data.get(\"recommendations\", []),\n",
    "                \"elevation\": parsed_data.get(\"elevation\", 50.0),\n",
    "                \"distance_from_water\": parsed_data.get(\"distance_from_water\", 1000.0),\n",
    "                \"image_analysis\": parsed_data.get(\"image_analysis\", \"\")\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"risk_level\": \"Medium\",\n",
    "                \"description\": \"Analysis completed\",\n",
    "                \"recommendations\": [\"Monitor weather conditions\", \"Stay informed about local alerts\"],\n",
    "                \"elevation\": 50.0,\n",
    "                \"distance_from_water\": 1000.0,\n",
    "                \"image_analysis\": response_text\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error parsing Gemini response: {str(e)}\")\n",
    "        return {\n",
    "            \"risk_level\": \"Medium\",\n",
    "            \"description\": \"Analysis completed\",\n",
    "            \"recommendations\": [\"Monitor weather conditions\", \"Stay informed about local alerts\"],\n",
    "            \"elevation\": 50.0,\n",
    "            \"distance_from_water\": 1000.0,\n",
    "            \"image_analysis\": response_text\n",
    "        }\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"Flood Detection API with Gemini AI\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"status\": \"healthy\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"ai_model\": \"Gemini 2.0 Flash\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def generate_image_risk_assessment() -> dict:\n",
    "    import random\n",
    "    risk_level = random.choice([\"Low\", \"Medium\", \"High\", \"Very High\"])\n",
    "    descriptions = {\n",
    "        \"Low\": \"Image analysis shows low flood risk terrain.\",\n",
    "        \"Medium\": \"Image analysis indicates moderate flood risk factors.\",\n",
    "        \"High\": \"Image analysis reveals high flood risk characteristics.\",\n",
    "        \"Very High\": \"Image analysis shows very high flood risk indicators.\"\n",
    "    }\n",
    "    recommendations = {\n",
    "        \"Low\": [\n",
    "            \"Continue monitoring terrain changes\",\n",
    "            \"Maintain current drainage systems\",\n",
    "            \"Stay informed about weather patterns\"\n",
    "        ],\n",
    "        \"Medium\": [\n",
    "            \"Improve drainage infrastructure\",\n",
    "            \"Consider flood monitoring systems\",\n",
    "            \"Develop emergency response plan\"\n",
    "        ],\n",
    "        \"High\": [\n",
    "            \"Install comprehensive flood barriers\",\n",
    "            \"Implement early warning systems\",\n",
    "            \"Consider structural reinforcements\"\n",
    "        ],\n",
    "        \"Very High\": [\n",
    "            \"Immediate flood protection measures needed\",\n",
    "            \"Consider relocation to higher ground\",\n",
    "            \"Implement comprehensive emergency protocols\"\n",
    "        ]\n",
    "    }\n",
    "    return {\n",
    "        \"risk_level\": risk_level,\n",
    "        \"description\": descriptions[risk_level],\n",
    "        \"recommendations\": recommendations[risk_level],\n",
    "        \"elevation\": round(random.uniform(10, 100), 1),\n",
    "        \"distance_from_water\": round(random.uniform(200, 2000), 1)\n",
    "    }\n",
    "\n",
    "@app.post(\"/api/analyze/image\")\n",
    "async def analyze_image(\n",
    "    file: UploadFile = File(...),\n",
    "    content_length: Optional[int] = Header(default=None)\n",
    "):\n",
    "    try:\n",
    "        logger.info(f\"Analyzing image: {file.filename}\")\n",
    "\n",
    "        # Validate MIME\n",
    "        if not file.content_type or not file.content_type.startswith(\"image/\"):\n",
    "            raise HTTPException(status_code=400, detail=\"File must be an image\")\n",
    "\n",
    "        # Pre-validate size using Content-Length when available (helps client-side)\n",
    "        # Also supports a hard limit of 10 MB\n",
    "        max_bytes = 10 * 1024 * 1024\n",
    "        if content_length is not None and content_length > max_bytes:\n",
    "            raise HTTPException(status_code=400, detail=\"File size must be less than 10MB\")\n",
    "\n",
    "        # Read data\n",
    "        image_data = await file.read()\n",
    "\n",
    "        # Optional server-side size validation if header missing\n",
    "        if len(image_data) > max_bytes:\n",
    "            raise HTTPException(status_code=400, detail=\"File size must be less than 10MB\")\n",
    "\n",
    "        # Load image with PIL\n",
    "        try:\n",
    "            image = PILImage.open(io.BytesIO(image_data))\n",
    "            if image.mode != \"RGB\":\n",
    "                image = image.convert(\"RGB\")\n",
    "        except Exception as img_error:\n",
    "            logger.error(f\"Error processing image: {str(img_error)}\")\n",
    "            raise HTTPException(status_code=400, detail=\"Invalid image format\")\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        Analyze this terrain image for flood risk assessment.\n",
    "\n",
    "        Please provide:\n",
    "        1. Risk Level (Low/Medium/High/Very High)\n",
    "        2. Description of the risk based on what you see\n",
    "        3. 3-5 specific recommendations\n",
    "        4. Estimated elevation in meters\n",
    "        5. Estimated distance from water bodies in meters\n",
    "        6. What water bodies or flood risks you can identify in the image\n",
    "\n",
    "        Format your response as JSON with these fields:\n",
    "        - risk_level\n",
    "        - description\n",
    "        - recommendations (array of strings)\n",
    "        - elevation (number)\n",
    "        - distance_from_water (number)\n",
    "        - image_analysis (string describing what you see)\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Using the latest google-genai client pattern\n",
    "            # Send text + inline image as a single contents list\n",
    "            parts = [\n",
    "                types.Part.from_text(prompt),\n",
    "                types.Part.from_bytes(data=image_data, mime_type=file.content_type or \"image/jpeg\")\n",
    "            ]\n",
    "            response = client.models.generate_content(\n",
    "                model=\"models/gemini-2.0-flash-exp\",\n",
    "                contents=[types.Content(role=\"user\", parts=parts)],\n",
    "                config=types.GenerateContentConfig(response_modalities=[\"TEXT\"])\n",
    "            )\n",
    "\n",
    "            # Concatenate any text parts\n",
    "            response_text = \"\"\n",
    "            if response and response.candidates:\n",
    "                for part in response.candidates.content.parts:\n",
    "                    if getattr(part, \"text\", None):\n",
    "                        response_text += part.text\n",
    "\n",
    "            parsed_data = parse_gemini_response(response_text or \"\")\n",
    "\n",
    "        except Exception as ai_error:\n",
    "            logger.error(f\"Error calling Gemini AI: {str(ai_error)}\")\n",
    "            parsed_data = generate_image_risk_assessment()\n",
    "            parsed_data[\"image_analysis\"] = \"Image analysis was not available, using simulated assessment\"\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            **parsed_data,\n",
    "            \"ai_analysis\": parsed_data.get(\"image_analysis\", \"\"),\n",
    "            \"message\": \"Image analysis completed successfully using Gemini AI\"\n",
    "        }\n",
    "\n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error analyzing image: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "import os\n",
    "\n",
    "host = os.environ.get(\"HOST\", \"0.0.0.0\")\n",
    "port = int(os.environ.get(\"PORT\", \"8000\"))\n",
    "\n",
    "print(f\"Starting Flood Detection Backend API on http://{host}:{port}\")\n",
    "print(f\"  - Swagger UI: http://{host}:{port}/docs\")\n",
    "print(f\"  - ReDoc: http://{host}:{port}/redoc\")\n",
    "print(f\"  - OpenAPI JSON: http://{host}:{port}/openapi.json\")\n",
    "\n",
    "config = uvicorn.Config(app, host=host, port=port, reload=False, log_level=\"info\")\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want a public URL (e.g., to test from a phone), use pyngrok.\n",
    "from pyngrok import ngrok\n",
    "\n",
    "public_url = ngrok.connect(addr=port, proto=\"http\")\n",
    "print(\"Public URL:\", public_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
